"""
–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenRouter —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ Tools
"""

import json
import os
from typing import Any

from openai import OpenAI


class OpenRouterClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenRouter API —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π tools"""

    def __init__(
        self,
        api_key: str | None = None,
        base_url: str = "https://openrouter.ai/api/v1",
        model: str = "openai/gpt-3.5-turbo",
    ):
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        self.client = OpenAI(base_url=base_url, api_key=self.api_key)
        self.model = model

    def convert_functions_to_tools(
        self, functions: list[dict[str, Any]]
    ) -> list[dict[str, Any]]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç functions –≤ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç tools"""
        return [{"type": "function", "function": func} for func in functions]

    def _get_cache_key(self, user_query: str, schemas_str: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        return f"{user_query}:{schemas_str}"

    def call_with_functions(
        self,
        user_query: str,
        function_schemas: list[dict[str, Any]],
        use_cache: bool = True,
        cache_dir: str | None = "test_results/cache",
        temperature: float = 0.1,
        max_tokens: int = 500,
    ) -> dict[str, Any]:
        """–í—ã–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –Ω–æ–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º tools"""
        tools = self.convert_functions_to_tools(function_schemas)

        schemas_str = json.dumps(function_schemas, sort_keys=True)
        cache_key = self._get_cache_key(user_query, schemas_str)

        # –µ—Å–ª–∏ –∫—ç—à –æ—Ç–∫–ª—é—á—ë–Ω
        if not use_cache or cache_dir is None:
            cache_file = None
        else:
            os.makedirs(cache_dir, exist_ok=True)
            safe_key = str(abs(hash(cache_key)))  # –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            cache_file = os.path.join(cache_dir, f"{safe_key}.json")

        # –µ—Å–ª–∏ –∫—ç—à –≤–∫–ª—é—á—ë–Ω –∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if cache_file and os.path.exists(cache_file):
            with open(cache_file, encoding="utf-8") as f:
                print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫–µ—à–∞: {cache_file}")
                return json.load(f)

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø–æ–º–æ–≥–∞—é—â–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (tools).",
                    },
                    {"role": "user", "content": user_query},
                ],
                tools=tools,
                tool_choice="auto",
                temperature=temperature,
                max_tokens=max_tokens,
            )

            message = response.choices[0].message
            result = {
                "user_query": user_query,
                "model": self.model,
                "timestamp": response.created,
                "message": {"content": message.content, "tool_calls": None},
            }

            if hasattr(message, "tool_calls") and message.tool_calls:
                tool_calls = []
                for tool_call in message.tool_calls:
                    if tool_call.type == "function":
                        tool_calls.append(
                            {
                                "id": tool_call.id,
                                "type": tool_call.type,
                                "function": {
                                    "name": tool_call.function.name,
                                    "arguments": json.loads(tool_call.function.arguments),
                                },
                            }
                        )
                result["message"]["tool_calls"] = tool_calls

                # –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
                if tool_calls:
                    result["message"]["function_call"] = {
                        "name": tool_calls[0]["function"]["name"],
                        "arguments": tool_calls[0]["function"]["arguments"],
                    }

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à, –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω
            if cache_file:
                with open(cache_file, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –∫–µ—à: {cache_file}")

            return result

        except Exception as e:
            return {
                "error": str(e),
                "user_query": user_query,
                "functions_called": [func["name"] for func in function_schemas],
            }


# –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
if __name__ == "__main__":
    import sys

    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("‚ùå –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENROUTER_API_KEY")
        sys.exit(1)

    try:
        client = OpenRouterClient(api_key=api_key)
        print("‚úÖ –ö–ª–∏–µ–Ω—Ç OpenRouter —Å–æ–∑–¥–∞–Ω (–Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç tools)")

        test_schema = {
            "name": "test_function",
            "description": "–¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è",
            "parameters": {
                "type": "object",
                "properties": {"message": {"type": "string", "description": "–°–æ–æ–±—â–µ–Ω–∏–µ"}},
                "required": ["message"],
            },
        }

        result = client.call_with_functions(
            user_query="–°–∫–∞–∂–∏ –ø—Ä–∏–≤–µ—Ç", function_schemas=[test_schema], use_cache=False
        )

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∞:")
        print(json.dumps(result, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
